{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7d3xuRaBXuHc"
      },
      "outputs": [],
      "source": [
        "# univariate lstm example\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing independent and dependent features\n",
        "def prepare_data(timeseries_data, n_features):\n",
        "\tX, y =[],[]\n",
        "\tfor i in range(len(timeseries_data)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_features\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(timeseries_data)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "kjHFCEnfXxwm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define input sequence\n",
        "timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = prepare_data(timeseries_data, n_steps)"
      ],
      "metadata": {
        "id": "K92_j-apXzTg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X),print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib6RhyZbX1OG",
        "outputId": "9f01b621-ca1d-427e-8ca6-3fa349ce18d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[110 125 133]\n",
            " [125 133 146]\n",
            " [133 146 158]\n",
            " [146 158 172]\n",
            " [158 172 187]\n",
            " [172 187 196]]\n",
            "[146 158 172 187 196 210]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3U1yMtXX2gv",
        "outputId": "92d91a96-044f-45be-9bab-0d6bf430a709"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "metadata": {
        "id": "ZYwbpyQTX5Hz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build LSTM Model"
      ],
      "metadata": {
        "id": "C_5iGXmcX8iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=300, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS7dzrMgX6YA",
        "outputId": "7e69fbf2-aea8-424f-cb04-1cb5521a08d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 3s 3s/step - loss: 32611.9375\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 32334.3027\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 32076.5254\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 31823.9375\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 31594.8066\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 31401.2891\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 31220.7676\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 31014.2285\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 30785.3926\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 30547.9707\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 30291.5254\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 29995.7832\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 29652.1699\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 29255.7285\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 28816.2012\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 28348.5938\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 27852.8672\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 27334.1699\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 26766.4590\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 26138.8379\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 25473.6641\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 24773.4277\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 24019.6348\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 23169.5156\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 22166.1094\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 20933.0078\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 19443.3613\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 17824.3379\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 16103.6553\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 14333.0000\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12666.0117\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11119.6025\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9614.4580\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8108.0352\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6597.6548\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5118.3989\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3729.1975\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2483.6890\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1427.0514\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 612.1979\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 127.4575\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 38.0805\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 303.3481\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 749.3979\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1149.8900\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1352.4506\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1334.8832\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1181.8009\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 979.7891\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 753.7346\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 525.1118\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 321.4942\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 164.0830\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 63.9030\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 20.6253\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.9340\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.6099\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 89.9878\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 127.5561\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 155.3952\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 169.9548\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 171.3339\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 161.4162\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 143.0411\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 119.2750\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 93.4038\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 68.5888\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 47.4019\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 31.5327\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.7075\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 17.7513\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 18.7453\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 23.2513\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 29.5822\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 36.0816\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.3701\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 44.5197\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 45.1313\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 43.3128\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 39.5737\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 34.6683\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 29.4255\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 24.5943\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 20.7335\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 18.1538\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 16.9120\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.8482\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 17.6518\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 18.9387\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 20.3250\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 21.4887\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 22.2082\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 22.3803\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 22.0143\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.2112\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 20.1310\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 18.9566\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 17.8595\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.9726\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.3742\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.0826\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 16.0625\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.2390\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 16.5173\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.8024\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 17.0158\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.1069\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 17.0580\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.8811\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.6112\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.2952\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 15.9813\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 15.7094\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.5051\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.3767\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 15.3176\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.3093\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.3269\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.3456\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 15.3447\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.3109\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.2399\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.1355\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 15.0076\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.8689\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.7329\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.6107\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.5092\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.4307\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.3731\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.3305\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.2947\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.2569\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.2096\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.1481\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.0721\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.9853\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.8940\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13.8050\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 13.7238\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.6526\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 13.5899\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.5312\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13.4702\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 13.3992\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.3093\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.1891\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.0238\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.7993\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.5424\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.5078\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.2204\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.8003\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.4025\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.8859\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.3406\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.2127\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6204\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6693\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3557\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8293\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9959\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3096\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2636\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0456\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.5366\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6380\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0457\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9736\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6418\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.3327\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.3074\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.9827\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.0452\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7759\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.9447\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7053\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8254\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6109\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.7630\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.5703\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6800\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5228\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6364\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4861\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5599\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4446\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5075\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3934\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4289\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3315\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3257\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2363\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3140\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3079\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1788\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.2501\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1297\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1959\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0999\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1406\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0593\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.0836\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.0141\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.0231\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.9799\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.9531\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9502\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8823\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8846\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8304\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.8132\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7731\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7255\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7087\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6479\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6133\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.5738\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5087\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4690\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4151\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3432\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2908\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2308\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1482\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0665\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9902\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9033\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8022\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6888\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5769\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4587\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3320\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1894\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0372\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8758\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7115\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5360\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3488\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1556\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9555\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8236\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1529\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6393\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8706\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9566\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8484\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1799\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1258\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0409\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1448\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9466\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7097\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8040\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8223\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8673\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5936\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6900\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8370\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8041\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6177\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7982\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0806\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5605\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0205\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6095\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7920\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5961\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6035\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6277\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5895\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4246\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5354\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4495\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3895\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3904\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4237\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3356\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4280\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2798\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3581\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3011\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2626\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2985\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2577\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2723\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2517\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2239\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2444\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2231\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2017\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2288\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2138\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1692\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2050\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2139\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1534\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1968\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2663\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb340482b80>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict for next 10 days data"
      ],
      "metadata": {
        "id": "bvFwKiJGYDUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate prediction for next 10 days\n",
        "x_input = np.array([187, 196, 210])\n",
        "temp_input=list(x_input)\n",
        "lst_output=[]\n",
        "i=0\n",
        "while(i<10):\n",
        "    \n",
        "    if(len(temp_input)>3):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        #print(x_input)\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.append(yhat[0][0])\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.append(yhat[0][0])\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    \n",
        "\n",
        "print(lst_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cViQug64X_Ff",
        "outputId": "c014ccbb-e237-483d-e8c9-b786d7e37905"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[223.22992]\n",
            "1 day input [196.         210.         223.22991943]\n",
            "1 day output [[233.19643]]\n",
            "2 day input [210.         223.22991943 233.19642639]\n",
            "2 day output [[247.23291]]\n",
            "3 day input [223.22992 233.19643 247.23291]\n",
            "3 day output [[259.9828]]\n",
            "4 day input [233.19643 247.23291 259.9828 ]\n",
            "4 day output [[271.82428]]\n",
            "5 day input [247.23291 259.9828  271.82428]\n",
            "5 day output [[286.3022]]\n",
            "6 day input [259.9828  271.82428 286.3022 ]\n",
            "6 day output [[299.84326]]\n",
            "7 day input [271.82428 286.3022  299.84326]\n",
            "7 day output [[313.71545]]\n",
            "8 day input [286.3022  299.84326 313.71545]\n",
            "8 day output [[329.19604]]\n",
            "9 day input [299.84326 313.71545 329.19604]\n",
            "9 day output [[344.3568]]\n",
            "[223.22992, 233.19643, 247.23291, 259.9828, 271.82428, 286.3022, 299.84326, 313.71545, 329.19604, 344.3568]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM31VojEZALr",
        "outputId": "b4940bb8-f013-44da-b6fc-5167c7773757"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[110, 125, 133, 146, 158, 172, 187, 196, 210]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(timeseries_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAGBrBzcZFED",
        "outputId": "6751d123-82ad-4d70-f1c9-6c6c3077aace"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trix5_7rZGT2",
        "outputId": "518342cf-13a9-47c0-98f8-b24af4e900d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[223.22992,\n",
              " 233.19643,\n",
              " 247.23291,\n",
              " 259.9828,\n",
              " 271.82428,\n",
              " 286.3022,\n",
              " 299.84326,\n",
              " 313.71545,\n",
              " 329.19604,\n",
              " 344.3568]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the Output"
      ],
      "metadata": {
        "id": "BX5q_nf7ZMEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "irsJFZvGZIyS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_new=np.arange(1,10)\n",
        "day_pred=np.arange(10,20)"
      ],
      "metadata": {
        "id": "hPBb8IoSZO2y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(day_new,timeseries_data)\n",
        "plt.plot(day_pred,lst_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fufhsm6wZQBm",
        "outputId": "08fabf53-4f40-4abe-f050-1f9850b1da20"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb333ee35b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQMp9mUEZRMw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}